# coding: utf-8

"""
    OpenAPI definition

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: v0
    Contact: support@gooddata.com
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr, field_validator
from typing import Any, ClassVar, Dict, List, Optional
from typing_extensions import Annotated
from gooddata_api_client.models.data_source_table_identifier import DataSourceTableIdentifier
from gooddata_api_client.models.declarative_aggregated_fact import DeclarativeAggregatedFact
from gooddata_api_client.models.declarative_attribute import DeclarativeAttribute
from gooddata_api_client.models.declarative_dataset_sql import DeclarativeDatasetSql
from gooddata_api_client.models.declarative_fact import DeclarativeFact
from gooddata_api_client.models.declarative_reference import DeclarativeReference
from gooddata_api_client.models.declarative_workspace_data_filter_column import DeclarativeWorkspaceDataFilterColumn
from gooddata_api_client.models.declarative_workspace_data_filter_references import DeclarativeWorkspaceDataFilterReferences
from gooddata_api_client.models.grain_identifier import GrainIdentifier
from typing import Optional, Set
from typing_extensions import Self

class DeclarativeDataset(BaseModel):
    """
    A dataset defined by its properties.
    """ # noqa: E501
    aggregated_facts: Optional[List[DeclarativeAggregatedFact]] = Field(default=None, description="An array of aggregated facts.", alias="aggregatedFacts")
    attributes: Optional[List[DeclarativeAttribute]] = Field(default=None, description="An array of attributes.")
    data_source_table_id: Optional[DataSourceTableIdentifier] = Field(default=None, alias="dataSourceTableId")
    description: Optional[Annotated[str, Field(strict=True, max_length=10000)]] = Field(default=None, description="A dataset description.")
    facts: Optional[List[DeclarativeFact]] = Field(default=None, description="An array of facts.")
    grain: List[GrainIdentifier] = Field(description="An array of grain identifiers.")
    id: Annotated[str, Field(strict=True)] = Field(description="The Dataset ID. This ID is further used to refer to this instance of dataset.")
    precedence: Optional[Annotated[int, Field(strict=True, ge=0)]] = Field(default=None, description="Precedence used in aggregate awareness.")
    references: List[DeclarativeReference] = Field(description="An array of references.")
    sql: Optional[DeclarativeDatasetSql] = None
    tags: Optional[List[StrictStr]] = Field(default=None, description="A list of tags.")
    title: Annotated[str, Field(strict=True, max_length=255)] = Field(description="A dataset title.")
    workspace_data_filter_columns: Optional[List[DeclarativeWorkspaceDataFilterColumn]] = Field(default=None, description="An array of columns which are available for match to implicit workspace data filters.", alias="workspaceDataFilterColumns")
    workspace_data_filter_references: Optional[List[DeclarativeWorkspaceDataFilterReferences]] = Field(default=None, description="An array of explicit workspace data filters.", alias="workspaceDataFilterReferences")
    __properties: ClassVar[List[str]] = ["aggregatedFacts", "attributes", "dataSourceTableId", "description", "facts", "grain", "id", "precedence", "references", "sql", "tags", "title", "workspaceDataFilterColumns", "workspaceDataFilterReferences"]

    @field_validator('id')
    def id_validate_regular_expression(cls, value):
        """Validates the regular expression"""
        if not re.match(r"^(?!\.)[.A-Za-z0-9_-]{1,255}$", value):
            raise ValueError(r"must validate the regular expression /^(?!\.)[.A-Za-z0-9_-]{1,255}$/")
        return value

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of DeclarativeDataset from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of each item in aggregated_facts (list)
        _items = []
        if self.aggregated_facts:
            for _item_aggregated_facts in self.aggregated_facts:
                if _item_aggregated_facts:
                    _items.append(_item_aggregated_facts.to_dict())
            _dict['aggregatedFacts'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in attributes (list)
        _items = []
        if self.attributes:
            for _item_attributes in self.attributes:
                if _item_attributes:
                    _items.append(_item_attributes.to_dict())
            _dict['attributes'] = _items
        # override the default output from pydantic by calling `to_dict()` of data_source_table_id
        if self.data_source_table_id:
            _dict['dataSourceTableId'] = self.data_source_table_id.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in facts (list)
        _items = []
        if self.facts:
            for _item_facts in self.facts:
                if _item_facts:
                    _items.append(_item_facts.to_dict())
            _dict['facts'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in grain (list)
        _items = []
        if self.grain:
            for _item_grain in self.grain:
                if _item_grain:
                    _items.append(_item_grain.to_dict())
            _dict['grain'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in references (list)
        _items = []
        if self.references:
            for _item_references in self.references:
                if _item_references:
                    _items.append(_item_references.to_dict())
            _dict['references'] = _items
        # override the default output from pydantic by calling `to_dict()` of sql
        if self.sql:
            _dict['sql'] = self.sql.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in workspace_data_filter_columns (list)
        _items = []
        if self.workspace_data_filter_columns:
            for _item_workspace_data_filter_columns in self.workspace_data_filter_columns:
                if _item_workspace_data_filter_columns:
                    _items.append(_item_workspace_data_filter_columns.to_dict())
            _dict['workspaceDataFilterColumns'] = _items
        # override the default output from pydantic by calling `to_dict()` of each item in workspace_data_filter_references (list)
        _items = []
        if self.workspace_data_filter_references:
            for _item_workspace_data_filter_references in self.workspace_data_filter_references:
                if _item_workspace_data_filter_references:
                    _items.append(_item_workspace_data_filter_references.to_dict())
            _dict['workspaceDataFilterReferences'] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of DeclarativeDataset from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "aggregatedFacts": [DeclarativeAggregatedFact.from_dict(_item) for _item in obj["aggregatedFacts"]] if obj.get("aggregatedFacts") is not None else None,
            "attributes": [DeclarativeAttribute.from_dict(_item) for _item in obj["attributes"]] if obj.get("attributes") is not None else None,
            "dataSourceTableId": DataSourceTableIdentifier.from_dict(obj["dataSourceTableId"]) if obj.get("dataSourceTableId") is not None else None,
            "description": obj.get("description"),
            "facts": [DeclarativeFact.from_dict(_item) for _item in obj["facts"]] if obj.get("facts") is not None else None,
            "grain": [GrainIdentifier.from_dict(_item) for _item in obj["grain"]] if obj.get("grain") is not None else None,
            "id": obj.get("id"),
            "precedence": obj.get("precedence"),
            "references": [DeclarativeReference.from_dict(_item) for _item in obj["references"]] if obj.get("references") is not None else None,
            "sql": DeclarativeDatasetSql.from_dict(obj["sql"]) if obj.get("sql") is not None else None,
            "tags": obj.get("tags"),
            "title": obj.get("title"),
            "workspaceDataFilterColumns": [DeclarativeWorkspaceDataFilterColumn.from_dict(_item) for _item in obj["workspaceDataFilterColumns"]] if obj.get("workspaceDataFilterColumns") is not None else None,
            "workspaceDataFilterReferences": [DeclarativeWorkspaceDataFilterReferences.from_dict(_item) for _item in obj["workspaceDataFilterReferences"]] if obj.get("workspaceDataFilterReferences") is not None else None
        })
        return _obj


